{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2408f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fd76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (220, 220)\n",
    "LABEL_COLUMNS = [\n",
    "    'Early Blight', 'Healthy', 'Late Blight', 'Leaf Miner', 'Leaf Mold',\n",
    "    'Mosaic Virus', 'Septoria', 'Spider Mites', 'Yellow Leaf Curl Virus'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e67331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalize(image):\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    if std == 0: std = 1e-6\n",
    "    return (image - mean) / std\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {path}\")\n",
    "    image = cv2.resize(image, IMAGE_SIZE)\n",
    "    image = image.astype(np.float32)\n",
    "    return z_score_normalize(image)\n",
    "\n",
    "def load_images_from_dataframe(df):\n",
    "    X, Y = [], []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            img = load_and_preprocess_image(row['filepath'])\n",
    "            X.append(img)\n",
    "            Y.append(row['labels'])\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "    return np.array(X, dtype=np.float32), np.array(Y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a399773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(folder_path):\n",
    "    df = pd.read_csv(os.path.join(folder_path, '_classes.csv'))\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df['filename'] = df['filename'].str.strip()\n",
    "    df['filepath'] = df['filename'].apply(lambda x: os.path.join(folder_path, x).replace('\\\\', '/'))\n",
    "    df = df[df['filepath'].apply(os.path.exists)].reset_index(drop=True)\n",
    "    df['labels'] = df[LABEL_COLUMNS].values.tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d47bc97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSVs...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading CSVs...\")\n",
    "df_train = prepare_dataframe(\"train\")\n",
    "df_valid = prepare_dataframe(\"valid\")\n",
    "df_test  = prepare_dataframe(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7235ed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9039/9039 [00:21<00:00, 411.35it/s]\n",
      "100%|██████████| 843/843 [00:08<00:00, 99.22it/s] \n",
      "100%|██████████| 165/165 [00:01<00:00, 105.84it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading images...\")\n",
    "X_train, Y_train = load_images_from_dataframe(df_train)\n",
    "X_valid, Y_valid = load_images_from_dataframe(df_valid)\n",
    "X_test, Y_test   = load_images_from_dataframe(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b7204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58463c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv layer 1\n",
    "    model.add(Conv2D(hp.Choice('conv1_filters', [16, 32]), (3, 3), activation='relu', input_shape=(220, 220, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Conv layer 2\n",
    "    model.add(Conv2D(hp.Choice('conv2_filters', [32, 64]), (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Conv layer 3\n",
    "    model.add(Conv2D(hp.Choice('conv3_filters', [64, 128]), (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(Dense(hp.Choice('dense1_units', [128, 256, 512]), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Choice('dropout1', [0.25, 0.3, 0.4])))\n",
    "\n",
    "    model.add(Dense(hp.Choice('dense2_units', [64, 128]), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Choice('dropout2', [0.25, 0.3])))\n",
    "\n",
    "    model.add(Dense(len(LABEL_COLUMNS), activation='sigmoid'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f0135d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 27m 27s]\n",
      "val_accuracy: 0.49466192722320557\n",
      "\n",
      "Best val_accuracy So Far: 0.49466192722320557\n",
      "Total elapsed time: 02h 26m 43s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='kt_trials',\n",
    "    project_name='tomato_leaf_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, Y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(X_valid, Y_valid),\n",
    "             batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "conv1_filters: 16\n",
      "conv2_filters: 64\n",
      "conv3_filters: 128\n",
      "dense1_units: 256\n",
      "dropout1: 0.4\n",
      "dense2_units: 64\n",
      "dropout2: 0.25\n",
      "learning_rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.values[param]}\")\n",
    "\n",
    "# Train the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
